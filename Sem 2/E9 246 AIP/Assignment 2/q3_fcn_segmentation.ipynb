{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIP_Assignment2_Q3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/b-basic/IISc-Assignments/blob/main/Sem%202/E9%20246%20AIP/Assignment%202/q3_fcn_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**---INSTRUCTIONS---**\n",
        "\n",
        "Please check the following link on how to import the kaggle dataset to google colab.\n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2021/06/how-to-load-kaggle-datasets-directly-into-google-colab/\n",
        "\n",
        "**--------------------------**"
      ],
      "metadata": {
        "id": "-A5uogkFV-Ql"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE** that Code given in the website is already written in **[1]** below. \n",
        "\n",
        "Just need to *download api credentials* (kaggle.json file) *from kaggle settings* as mentioned in step 2 of the link, and *then upload it on colab* as mentioned in step 3, and then run the code below. "
      ],
      "metadata": {
        "id": "N0MoTbGzWR1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download dansbecker/cityscapes-image-pairs\n",
        "! unzip cityscapes-image-pairs"
      ],
      "metadata": {
        "id": "fmc_JE7Fo7uB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plot\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Input, Conv2D, Activation, Add, Conv2DTranspose\n",
        "\n",
        "import gc # needed for garbage collection to avoid ram exhaustion while training"
      ],
      "metadata": {
        "id": "uOuZeQBFmMin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(f_name, path):\n",
        "    image = Image.open(os.path.join(path, f_name))\n",
        "    image = np.array(image)\n",
        "    \n",
        "    # train set images contains actual image on left and segment map of image \n",
        "    # on right, side by side in single image file\n",
        "    img = image[:,:256]\n",
        "    seg_mask = image[:,256:]\n",
        "    \n",
        "    return img, seg_mask"
      ],
      "metadata": {
        "id": "2IARH5qHnJM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# params required for functions below\n",
        "# height, width and classes all are properties of the dataset we are working with\n",
        "width = 256\n",
        "height = 256\n",
        "classes = 13"
      ],
      "metadata": {
        "id": "L7I_Yzdxv-Lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# binning pixel values from range (0, 255) to (0, 13) where 13 is the # of classes.\n",
        "def bin_image(seg_mask):\n",
        "    bins = np.array([20, 40, 60, 80, 100, 120, 140, 160, 180, 200, 220, 240])\n",
        "    new_mask = np.digitize(seg_mask, bins)\n",
        "    return new_mask"
      ],
      "metadata": {
        "id": "vfiR6uUtnNZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the rgb segmentation maps to categorical maps (using new mask that we got by binning) \n",
        "# this will be used for training our model\n",
        "def get_segmentation(new_mask, classes, width=width, height=height):\n",
        "    segment_labels = np.zeros((height, width, classes))\n",
        "    n_m = new_mask[:, : , 0]\n",
        "\n",
        "    # one hot encoding of each pixel to its class number\n",
        "    for c in range(classes):\n",
        "        segment_labels[:, :, c] = (n_m == c ).astype(int)\n",
        "    return segment_labels"
      ],
      "metadata": {
        "id": "2RYIhWgJnQnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# categorized segment maps back to colored segmentation maps for visualization\n",
        "def color_segmented(seg, num_classes):\n",
        "    seg_img = np.zeros((seg.shape[0],seg.shape[1],3)).astype('float')\n",
        "    colors = sns.color_palette(\"hls\", num_classes)\n",
        "    \n",
        "    for c in range(num_classes):\n",
        "        seg_c = (seg == c)\n",
        "        seg_img[:,:,0] += (seg_c*( colors[c][0] ))\n",
        "        seg_img[:,:,1] += (seg_c*( colors[c][1] ))\n",
        "        seg_img[:,:,2] += (seg_c*( colors[c][2] ))\n",
        "\n",
        "    return seg_img"
      ],
      "metadata": {
        "id": "Eb6U8WuAnSMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  returns data in form of batches\n",
        "# notice 'yield' keyword instead of 'return', that too inside of the for loop\n",
        "def data_gen(path, batch_size=10, classes=13):\n",
        "    files = os.listdir(path)\n",
        "    while True:\n",
        "        for i in range(0, len(files), batch_size):\n",
        "            batch_files = files[i : i+batch_size]\n",
        "            imgs=[]\n",
        "            segs=[]\n",
        "            for file in batch_files:\n",
        "                image, mask = load_image(file, path)\n",
        "                mask_binned = bin_image(mask)\n",
        "                labels = get_segmentation(mask_binned, classes)\n",
        "\n",
        "                imgs.append(image)\n",
        "                segs.append(labels)\n",
        "\n",
        "            yield np.array(imgs), np.array(segs)"
      ],
      "metadata": {
        "id": "vgnfFr3XnT7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # make sure you have followed the instructions on top of this page before running this\n",
        "\n",
        "train_dir=\"/content/cityscapes_data/cityscapes_data/train\"\n",
        "valid_dir=\"/content/cityscapes_data/cityscapes_data/val\"\n",
        "\n",
        "num_of_training_samples = len(os.listdir(train_dir)) \n",
        "num_of_testing_samples = len(os.listdir(valid_dir))"
      ],
      "metadata": {
        "id": "QE0QPLd-mj79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "\n",
        "train_gen = data_gen(train_dir, batch_size=batch_size)\n",
        "val_gen = data_gen(valid_dir, batch_size=batch_size)\n",
        "imgs, segs = next(train_gen)\n",
        "imgs.shape, segs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcasEvR2nU0w",
        "outputId": "5b3b2b5f-052e-4742-fd5f-ce08627852c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10, 256, 256, 3), (10, 256, 256, 13))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # just to check output of above color_segmented() on a single image\n",
        "\n",
        "# image = imgs[0]\n",
        "# mask = color_segmented(np.argmax(segs[0], axis=-1),classes) # argmax basically reverses the one hot encoding\n",
        "# masked_image = cv2.addWeighted(image/255, 0.5, mask, 0.5, 0)\n",
        "\n",
        "# fig, axs = plot.subplots(1, 3, figsize=(20,20))\n",
        "# axs[0].imshow(image)\n",
        "# axs[0].set_title('Original Image')\n",
        "# axs[1].imshow(mask)\n",
        "# axs[1].set_title('Segmentation Mask')\n",
        "# axs[2].imshow(masked_image)\n",
        "# axs[2].set_title('Masked Image')\n",
        "# plot.show()"
      ],
      "metadata": {
        "id": "-GDoncOunmYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating model by adding layers to pre-trained vgg network\n",
        "vgg = VGG16(include_top=False, weights='imagenet', input_shape=(width, height, 3))\n",
        "pool5 = vgg.get_layer('block5_pool').output \n",
        "\n",
        "# adding layers\n",
        "conv_6 = Conv2D(1024, (7, 7), activation='relu', padding='same', name=\"conv_6\")(pool5)\n",
        "conv_7 = Conv2D(1024, (1, 1), activation='relu', padding='same', name=\"conv_7\")(conv_6)\n",
        "deconv_8 = Conv2DTranspose(classes, kernel_size=(32,32), strides=(32,32))(conv_7)\n",
        "output_layer = Activation('softmax')(deconv_8)\n",
        "\n",
        "model = Model(inputs=vgg.input, outputs=output_layer)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "IZPaXyFcnt78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model)"
      ],
      "metadata": {
        "id": "EcNVXJKLn14u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adam = Adam(learning_rate=0.001, decay=1e-06)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"best-model-vgg.hdf5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "# # for RAM limit issues\n",
        "# class MyCustomCallback(tf.keras.callbacks.Callback):\n",
        "#   def on_epoch_end(self, epoch, logs=None):\n",
        "#     gc.collect()\n",
        "# callbacks_list = [checkpoint, MyCustomCallback()]\n",
        "\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "# # in case of colab session timeout / ram exceeded, to resume from a checkpoint. remember to change \n",
        "# # \"model.fit(..)\" below to \"prev_best_model.fit(..)\"\n",
        "# prev_best_model = load_model(\"best-model-vgg.hdf5\")\n",
        "\n",
        "history = model.fit(train_gen, epochs=4, steps_per_epoch=num_of_training_samples//batch_size,\n",
        "                       validation_data=val_gen, validation_steps=num_of_testing_samples//batch_size,\n",
        "                       callbacks=callbacks_list, use_multiprocessing=True)\n",
        "\n",
        "# history = prev_best_model.fit(train_gen, epochs=1, steps_per_epoch=num_of_training_samples//batch_size,\n",
        "#                        validation_data=val_gen, validation_steps=num_of_testing_samples//batch_size,\n",
        "#                        callbacks=callbacks_list, use_multiprocessing=True)"
      ],
      "metadata": {
        "id": "-3TECrcon6lL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(\"best-model-vgg.hdf5\")\n",
        "loss = history.history[\"val_loss\"]\n",
        "acc = history.history[\"val_accuracy\"] #accuracy\n",
        "\n",
        "plot.figure(figsize=(12, 6))\n",
        "plot.subplot(211)\n",
        "plot.title(\"Val. Loss\")\n",
        "plot.plot(loss)\n",
        "plot.xlabel(\"Epoch\")\n",
        "plot.ylabel(\"Loss\")\n",
        "\n",
        "plot.subplot(212)\n",
        "plot.title(\"Val. Accuracy\")\n",
        "plot.plot(acc)\n",
        "plot.xlabel(\"Epoch\")\n",
        "plot.ylabel(\"Accuracy\")\n",
        "\n",
        "plot.tight_layout()\n",
        "plot.savefig(\"learn.png\", dpi=150)\n",
        "plot.show()"
      ],
      "metadata": {
        "id": "0uqj1WCYn_mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing on a validation set image\n",
        "\n",
        "im, seg = next(val_gen)\n",
        "pred = model.predict(im)\n",
        "\n",
        "i = 0\n",
        "\n",
        "p = color_segmented(np.argmax(pred[i], axis=-1), classes)\n",
        "s = color_segmented(np.argmax(seg[i], axis=-1), classes)\n",
        "\n",
        "pred_im = cv2.addWeighted(im[i]/255, 0.5, p, 0.5, 0)\n",
        "true_im = cv2.addWeighted(im[i]/255, 0.5, s, 0.5, 0)\n",
        "\n",
        "plot.figure(figsize=(12,6))\n",
        "plot.subplot(121)\n",
        "plot.title(\"Prediction\")\n",
        "plot.imshow(pred_im)\n",
        "plot.axis(\"off\")\n",
        "plot.subplot(122)\n",
        "plot.title(\"Original\")\n",
        "plot.imshow(true_im)\n",
        "plot.axis(\"off\")\n",
        "plot.tight_layout()\n",
        "plot.savefig(\"pred_\"+str(i)+\".png\", dpi=150)\n",
        "plot.show()"
      ],
      "metadata": {
        "id": "3OCB8A91oDe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BELOW CODE USED TO TEST ON CUSTOM IMAGES.\n",
        "\n",
        "NEED TO EXECUTE FOLLOWING CELLS ABOVE FIRST:\n",
        "\n",
        "-cell with import statements\n",
        "\n",
        "-cell with color_segmented() function\n",
        "\n",
        "-cell with model definition"
      ],
      "metadata": {
        "id": "VDcLRRMPwYn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # link drive to colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# # copy from colab to linked drive\n",
        "# %cp /content/best-model-vgg.hdf5 /content/drive/My\\ Drive\n",
        "\n",
        "# # copy from linked drive to colab\n",
        "# %cp /content/drive/My\\ Drive/best-model-vgg.hdf5 /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUlRM__fiyjL",
        "outputId": "cae651df-8bec-4dc3-d238-db88b77780cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(\"best-model-vgg.hdf5\")\n",
        "image = Image.open(\"/content/natural_im2.jpg\")\n",
        "newsize = (256, 256)\n",
        "im = image.resize(newsize)\n",
        "im = np.array(im)\n",
        "# plot.imshow(im)\n",
        "# plot.show()\n",
        "im = np.expand_dims(im, 0)\n",
        "# print(im.shape)\n",
        "\n",
        "pred = model.predict(im)\n",
        "_p = color_segmented(np.argmax(pred[0], axis=-1), classes)\n",
        "predimg = cv2.addWeighted(im[0]/255, 0.5, _p, 0.5, 0)\n",
        "plot.subplot(111)\n",
        "plot.title(\"Prediction\")\n",
        "plot.imshow(predimg)\n",
        "plot.show()"
      ],
      "metadata": {
        "id": "NwBBYCBb8jeO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}